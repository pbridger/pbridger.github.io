<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on paulbridger.com</title>
    <link>https://paulbridger.com/posts/</link>
    <description>Recent content in Posts on paulbridger.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Sep 2020 08:43:23 +0200</lastBuildDate><atom:link href="https://paulbridger.com/posts/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>A Simple and Flexible Pytorch Video Pipeline</title>
      <link>https://paulbridger.com/posts/video_analytics_pytorch_pipeline/</link>
      <pubDate>Wed, 23 Sep 2020 18:21:00 +0200</pubDate>
      
      <guid>https://paulbridger.com/posts/video_analytics_pytorch_pipeline/</guid>
      <description>Taking machine learning models into production for video analytics doesn&amp;rsquo;t have to be hard. A pipeline with reasonable efficiency can be created very quickly just by plugging together the right libraries. In this post we&amp;rsquo;ll create a video pipeline with a focus on flexibility and simplicity using two main libraries: &lt;a href=&#34;https://gstreamer.freedesktop.org/&#34;&gt;Gstreamer&lt;/a&gt; and &lt;a href=&#34;https://pytorch.org&#34;&gt;Pytorch&lt;/a&gt;.</description>
    </item>
    
    <item>
      <title>Object Detection from 9 FPS to 650 FPS in 6 Steps</title>
      <link>https://paulbridger.com/posts/video_analytics_pipeline_tuning/</link>
      <pubDate>Wed, 30 Sep 2020 08:43:23 +0200</pubDate>
      
      <guid>https://paulbridger.com/posts/video_analytics_pipeline_tuning/</guid>
      <description>Making code run fast on GPUs requires a very different approach to making code run fast on CPUs because the hardware architecture is fundamentally different. Machine learning engineers of all kinds should care about squeezing performance from their models and hardware â€” not just for production purposes, but also for research and training. In research as in development, a fast iteration loop leads to faster improvement. This article is a practical deep dive into making a specific deep learning model (&lt;a href=&#34;https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/&#34;&gt;Nvidia&amp;rsquo;s SSD300&lt;/a&gt;) run fast on a powerful GPU server, but the general principles apply to all GPU programming.</description>
    </item>
    
    <item>
      <title>About Me</title>
      <link>https://paulbridger.com/posts/about/</link>
      <pubDate>Wed, 23 Sep 2020 01:14:00 +0200</pubDate>
      
      <guid>https://paulbridger.com/posts/about/</guid>
      <description>Hi. I&amp;rsquo;m Paul, and I like to write code, build products and start companies.
I started out in New Zealand, and I&amp;rsquo;ve been lucky enough to work and start companies with some very special people in many places around the world. I&amp;rsquo;ve often played a technical co-founder role, leading and growing teams, and taking complex products from conception to production.
Over the last couple of decades I&amp;rsquo;ve built products in a wide range of industries, from publishing, 3D game development, investment banking, to iOS, big data and machine learning.</description>
    </item>
    
  </channel>
</rss>
