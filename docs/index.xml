<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docs on paulbridger.com</title>
    <link>https://paulbridger.com/docs/</link>
    <description>Recent content in Docs on paulbridger.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Sep 2020 08:43:23 +0200</lastBuildDate><atom:link href="https://paulbridger.com/docs/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>From 10 FPS to 650 FPS: Making Deep Learning Fast</title>
      <link>https://paulbridger.com/docs/video_analytics_pipeline_tuning/</link>
      <pubDate>Wed, 30 Sep 2020 08:43:23 +0200</pubDate>
      
      <guid>https://paulbridger.com/docs/video_analytics_pipeline_tuning/</guid>
      <description>Making code run fast on GPUs requires a very different approach to making code run fast on CPUs because the hardware architecture is fundamentally different. This article is a practical deep dive into making a specific deep learning model (&lt;a href=&#34;https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/&#34;&gt;Nvidia&amp;rsquo;s SSD300&lt;/a&gt;) run fast on a powerful GPU server, but the general principles apply to all GPU programming. Machine learning engineers of all kinds should care about squeezing performance from their models and hardware â€” not just for production purposes, but also for research and training. In research as in development, a fast iteration loop leads to faster improvement.</description>
    </item>
    
    <item>
      <title>A Simple and Flexible Pytorch Video Pipeline</title>
      <link>https://paulbridger.com/docs/video_analytics_pytorch_pipeline/</link>
      <pubDate>Wed, 23 Sep 2020 18:21:00 +0200</pubDate>
      
      <guid>https://paulbridger.com/docs/video_analytics_pytorch_pipeline/</guid>
      <description>A Simple and Flexible Pytorch Video Pipeline #  Intro #  Taking machine learning models into production for video analytics doesn&amp;rsquo;t have to be hard. A pipeline with reasonable efficiency can be created very quickly just by plugging together the right libraries. In this post we&amp;rsquo;ll create a video pipeline with a focus on flexibility and simplicity using two main libraries: Gstreamer and Pytorch.
Performance is out of scope for this first step, but we&amp;rsquo;ll do a deep dive in a later article.</description>
    </item>
    
  </channel>
</rss>
