<!DOCTYPE html>
<html lang="en" dir=>

<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Intro #  Taking machine learning models into production for video analytics doesn&rsquo;t have to be hard. A pipeline with reasonable efficiency can be created very quickly just by plugging together the right libraries. In this post we&rsquo;ll create a video pipeline with a focus on flexibility and simplicity using two main libraries: Gstreamer and Pytorch.
Performance is out of scope for this first step, but we&rsquo;ll do a deep dive in a later article.">
<meta name="theme-color" content="#FFFFFF"><meta property="og:title" content="A Simple and Flexible Pytorch Video Pipeline" />
<meta property="og:description" content="Intro #  Taking machine learning models into production for video analytics doesn&rsquo;t have to be hard. A pipeline with reasonable efficiency can be created very quickly just by plugging together the right libraries. In this post we&rsquo;ll create a video pipeline with a focus on flexibility and simplicity using two main libraries: Gstreamer and Pytorch.
Performance is out of scope for this first step, but we&rsquo;ll do a deep dive in a later article." />
<meta property="og:type" content="article" />
<meta property="og:url" content="pbridger.github.io/docs/video_analytics_pytorch_pipeline/" />
<meta property="article:published_time" content="2020-08-23T08:43:23+02:00" />
<meta property="article:modified_time" content="2020-08-23T08:43:23+02:00" />
<title>A Simple and Flexible Pytorch Video Pipeline | paulbridger.com</title>
<link rel="manifest" href="/pbridger.github.io/manifest.json">
<link rel="icon" href="/pbridger.github.io/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/pbridger.github.io/book.min.91028b48a67fc5617943c8dc17236b59e64a3c795f22aad952c461c055582264.css" integrity="sha256-kQKLSKZ/xWF5Q8jcFyNrWeZKPHlfIqrZUsRhwFVYImQ=">
<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-XXXXXXXXX-X', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>
<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->

  
</head>

<body dir=>
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      
  <nav>
<h2 class="book-brand">
  <a href="/pbridger.github.io"><span>paulbridger.com</span>
  </a>
</h2>












  



  
  
  
  

  
  <ul>
    
      
        <li>
          
  
    <a href="pbridger.github.io/docs/video_analytics_pytorch_pipeline/" class="active">A Simple and Flexible Pytorch Video Pipeline</a>
  

        </li>
      
    
      
        <li>
          
  
    <a href="pbridger.github.io/docs/video_analytics_pipeline_tuning/" class="">From 10 FPS to 650 FPS: Making Deep Learning Fast</a>
  

        </li>
      
    
  </ul>
  















</nav>




  <script>(function(){var menu=document.querySelector("aside.book-menu nav");addEventListener("beforeunload",function(event){localStorage.setItem("menu.scrollTop",menu.scrollTop);});menu.scrollTop=localStorage.getItem("menu.scrollTop");})();</script>


 
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/pbridger.github.io/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>A Simple and Flexible Pytorch Video Pipeline</strong>

  <label for="toc-control">
    
    <img src="/pbridger.github.io/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  <nav id="TableOfContents">
  <ul>
    <li><a href="#intro">Intro</a></li>
    <li><a href="#step-0-baseline-cli-gstreamer-pipeline">Step 0: Baseline CLI Gstreamer pipeline</a></li>
    <li><a href="#step-1-get-frames-into-python">Step 1: Get frames into Python</a></li>
    <li><a href="#step-2-get-frames-into-pytorch">Step 2: Get frames into Pytorch</a></li>
  </ul>
</nav>


  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h2 id="intro">
  Intro
  <a class="anchor" href="#intro">#</a>
</h2>
<p>Taking machine learning models into production for video analytics doesn&rsquo;t have to be hard. A pipeline with reasonable efficiency can be created very quickly just by plugging together the right libraries. In this post we&rsquo;ll create a video pipeline with a focus on flexibility and simplicity using two main libraries: <a href="https://gstreamer.freedesktop.org/">Gstreamer</a> and <a href="https://pytorch.org">Pytorch</a>.</p>
<p>Performance is out of scope for this first step, but we&rsquo;ll do a deep dive in a later article. Worthwhile throughput improvements are possible with a little effort. We&rsquo;ll also ignore black-box serving toolkits (Nvidia Triton/TensorRT, Kubeflow, TorchServe etc.) so we can understand what&rsquo;s happening end to end.</p>
<p>The main library we&rsquo;ll be using is <a href="https://gstreamer.freedesktop.org/">Gstreamer</a>, a very flexible and efficient media-processing pipeline that comes with a huge ecosystem of components. In principle these components can be seamlessly swapped out to support different codecs, transformations and outputs but in practice constructing a Gstreamer pipeline can be a tricky process with a lot of iteration.</p>
<p>I&rsquo;ve created a repo with some example code here: <a href="https://github.com/pbridger/pytorch-video-pipeline">https://github.com/pbridger/pytorch-video-pipeline</a>
Besides the code, the repo contains a Dockerfile and top-level Makefile to make running the scripts easy.</p>
<h2 id="step-0-baseline-cli-gstreamer-pipeline">
  Step 0: Baseline CLI Gstreamer pipeline
  <a class="anchor" href="#step-0-baseline-cli-gstreamer-pipeline">#</a>
</h2>
<p>In order to show the basic Gstreamer pipeline components and to validate the container environment, we can run something like this from the CLI:</p>
<pre><code>$ gst-launch-1.0 filesrc location=media/in.mp4 ! decodebin ! progressreport update-freq=1 ! fakesink sync=true
</code></pre><p>Running this will show the video file being read (by the <code>filesrc</code> element), decoded (<code>decodebin</code> element) and sent to the Gstreamer equivalent of /dev/null (<code>fakesink</code> element).</p>
<p>If you don&rsquo;t have Gstreamer installed, the easiest way to do this is to use the makefile from the repo. Grab the repo from github, then use this make target:</p>
<pre><code>$ make cli.pipeline.png
</code></pre><p>Alternatively, start the Docker container using the makefile and run the above gst-launch-1.0 command from within:</p>
<pre><code>$ make run-container
...
/app# gst-launch-1.0 filesrc location=media/in.mp4 ! decodebin ! progressreport update-freq=1 ! fakesink sync=true
</code></pre><p>Output should look something like this:</p>
<details >
  <summary>Output: CLI Gstreamer</summary>
  <div>
    

<figure style="margin: 2rem 0">
    <img src="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/cli.output.svg">
</figure>


  </div>
</details>

<p>Gstreamer is able to generate a representation showing the transformations in the pipeline, see below:</p>
<details >
  <summary>Pipeline: CLI Gstreamer</summary>
  <div>
    








<a href="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/cli.pipeline.png">
    <figure style="margin: 2rem 0">
        <img style="max-width: 100%; width: auto; height: auto;" src="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/cli.pipeline_hu1961d2a9818f6bc6d76dbf2f043727e4_198140_800x0_resize_box_2.png" width="800" height="54">
        <figcaption><small></small></figcaption>
    </figure>
</a>


  </div>
</details>

<h2 id="step-1-get-frames-into-python">
  Step 1: Get frames into Python
  <a class="anchor" href="#step-1-get-frames-into-python">#</a>
</h2>
<p>Since we want to feed these frames into a Pytorch model running in the Python runtime we&rsquo;ll construct a similar pipeline from a script:</p>














<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">gi</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;Gst&#39;</span><span class="p">,</span> <span class="s1">&#39;1.0&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">gi.repository</span> <span class="kn">import</span> <span class="n">Gst</span>

<span class="n">frame_format</span> <span class="o">=</span> <span class="s1">&#39;RGBA&#39;</span>

<span class="n">Gst</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Gst</span><span class="o">.</span><span class="n">parse_launch</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;&#39;&#39;
</span><span class="s1">    filesrc location=media/in.mp4 num-buffers=200 !
</span><span class="s1">    decodebin !
</span><span class="s1">    fakesink name=s
</span><span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_frame_probe</span><span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
    <span class="n">buf</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;[{buf.pts / Gst.SECOND:6.2f}]&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeReturn</span><span class="o">.</span><span class="n">OK</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">get_by_name</span><span class="p">(</span><span class="s1">&#39;s&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_static_pad</span><span class="p">(</span><span class="s1">&#39;sink&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">add_probe</span><span class="p">(</span>
    <span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeType</span><span class="o">.</span><span class="n">BUFFER</span><span class="p">,</span>
    <span class="n">on_frame_probe</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">State</span><span class="o">.</span><span class="n">PLAYING</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">get_bus</span><span class="p">()</span><span class="o">.</span><span class="n">timed_pop_filtered</span><span class="p">(</span>
            <span class="n">Gst</span><span class="o">.</span><span class="n">SECOND</span><span class="p">,</span>
            <span class="n">Gst</span><span class="o">.</span><span class="n">MessageType</span><span class="o">.</span><span class="n">EOS</span> <span class="o">|</span> <span class="n">Gst</span><span class="o">.</span><span class="n">MessageType</span><span class="o">.</span><span class="n">ERROR</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">msg</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">msg</span><span class="o">.</span><span class="n">get_structure</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span> <span class="k">if</span> <span class="n">msg</span><span class="o">.</span><span class="n">get_structure</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
            <span class="n">msg_type</span> <span class="o">=</span> <span class="n">Gst</span><span class="o">.</span><span class="n">message_type_get_name</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;{msg.src.name}: [{msg_type}] {text}&#39;</span><span class="p">)</span>
            <span class="k">break</span>
<span class="k">finally</span><span class="p">:</span>
    <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;logs/{os.path.splitext(sys.argv[0])[0]}.pipeline.dot&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
        <span class="n">Gst</span><span class="o">.</span><span class="n">debug_bin_to_dot_data</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">Gst</span><span class="o">.</span><span class="n">DebugGraphDetails</span><span class="o">.</span><span class="n">ALL</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">State</span><span class="o">.</span><span class="n">NULL</span><span class="p">)</span>
</code></pre></div>

<p>The above code runs the same filesrc-decode pipeline, monitoring the pipeline for errors and end of stream (EOS) messages, and installs a probe callback (<code>on_frame_probe</code>) which will be called for every frame processed. This is about as simple as I could make it. With this code we have video frames/buffers available within the Python callback as Gstreamer buffers.</p>
<p>To run this using the makefile:</p>
<pre><code>$ make frames_into_python.pipeline.png
</code></pre><p>As you can see from the <code>Gst.parse_launch</code> call the constructed pipeline is even simpler than the CLI version since we don&rsquo;t bother with the <code>progressreport</code> element. Also, because we removed the <code>sync=true</code> parameter from the fakesink element the pipeline runs as fast as the slowest pipeline element instead of synchronizing with the clock:</p>
<details >
  <summary>Output: frames_into_python.py</summary>
  <div>
    

<figure style="margin: 2rem 0">
    <img src="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/frames_into_python.output.svg">
</figure>


  </div>
</details>

<details >
  <summary>Pipeline: frames_into_python.py</summary>
  <div>
    








<a href="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/frames_into_python.pipeline.png">
    <figure style="margin: 2rem 0">
        <img style="max-width: 100%; width: auto; height: auto;" src="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/frames_into_python.pipeline_hu8862f21746f9d6519809566160033120_170616_800x0_resize_box_2.png" width="800" height="60">
        <figcaption><small></small></figcaption>
    </figure>
</a>


  </div>
</details>

<h2 id="step-2-get-frames-into-pytorch">
  Step 2: Get frames into Pytorch
  <a class="anchor" href="#step-2-get-frames-into-pytorch">#</a>
</h2>
<p>Now we&rsquo;ll include logic to add two things to the <code>on_frame_probe</code> callback:</p>
<ol>
<li>Reinterpret and copy the decoded Gstreamer buffer into Pytorch tensor.</li>
<li>Run some basic object detection on the image tensor using <a href="https://pytorch.org/hub/nvidia_deeplearningexamples_ssd/">Nvidia&rsquo;s SSD300</a>.</li>
</ol>
<p>In the interests of keeping the code short and simple this sample has some deliberate limitations:</p>
<ul>
<li>Incomplete image preprocessing.</li>
<li>No inference post-processing, so we don&rsquo;t even get bounding boxes to print.</li>
<li>No emphasis whatsoever on performance except for running on CUDA/GPU if available.</li>
</ul>














<div class="highlight"><pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">import</span> <span class="nn">os</span><span class="o">,</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">gi</span>
<span class="n">gi</span><span class="o">.</span><span class="n">require_version</span><span class="p">(</span><span class="s1">&#39;Gst&#39;</span><span class="p">,</span> <span class="s1">&#39;1.0&#39;</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">gi.repository</span> <span class="kn">import</span> <span class="n">Gst</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="kn">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span><span class="o">,</span> <span class="nn">torchvision</span>

<span class="n">frame_format</span><span class="p">,</span> <span class="n">pixel_bytes</span> <span class="o">=</span> <span class="s1">&#39;RGBA&#39;</span><span class="p">,</span> <span class="mi">4</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s1">&#39;cuda&#39;</span> <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">is_available</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;cpu&#39;</span><span class="p">)</span>
<span class="n">detector</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">hub</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s1">&#39;NVIDIA/DeepLearningExamples:torchhub&#39;</span><span class="p">,</span> <span class="s1">&#39;nvidia_ssd&#39;</span><span class="p">,</span> <span class="n">model_math</span><span class="o">=</span><span class="s1">&#39;fp32&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">eval</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
<span class="n">preprocess</span> <span class="o">=</span> <span class="n">torchvision</span><span class="o">.</span><span class="n">transforms</span><span class="o">.</span><span class="n">ToTensor</span><span class="p">()</span>

<span class="n">Gst</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>
<span class="n">pipeline</span> <span class="o">=</span> <span class="n">Gst</span><span class="o">.</span><span class="n">parse_launch</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;&#39;&#39;
</span><span class="s1">    filesrc location=media/in.mp4 num-buffers=200 !
</span><span class="s1">    decodebin !
</span><span class="s1">    nvvideoconvert !
</span><span class="s1">    video/x-raw,format={frame_format} !
</span><span class="s1">    fakesink name=s
</span><span class="s1">&#39;&#39;&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">on_frame_probe</span><span class="p">(</span><span class="n">pad</span><span class="p">,</span> <span class="n">info</span><span class="p">):</span>
    <span class="n">buf</span> <span class="o">=</span> <span class="n">info</span><span class="o">.</span><span class="n">get_buffer</span><span class="p">()</span>
    <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;[{buf.pts / Gst.SECOND:6.2f}]&#39;</span><span class="p">)</span>

    <span class="n">image_tensor</span> <span class="o">=</span> <span class="n">buffer_to_image_tensor</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="n">pad</span><span class="o">.</span><span class="n">get_current_caps</span><span class="p">())</span>
    <span class="n">image_batch</span> <span class="o">=</span> <span class="n">image_tensor</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
        <span class="n">detections</span> <span class="o">=</span> <span class="n">detector</span><span class="p">(</span><span class="n">image_batch</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeReturn</span><span class="o">.</span><span class="n">OK</span>

<span class="k">def</span> <span class="nf">buffer_to_image_tensor</span><span class="p">(</span><span class="n">buf</span><span class="p">,</span> <span class="n">caps</span><span class="p">):</span>
    <span class="n">caps_structure</span> <span class="o">=</span> <span class="n">caps</span><span class="o">.</span><span class="n">get_structure</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
    <span class="n">height</span><span class="p">,</span> <span class="n">width</span> <span class="o">=</span> <span class="n">caps_structure</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="s1">&#39;height&#39;</span><span class="p">),</span> <span class="n">caps_structure</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="s1">&#39;width&#39;</span><span class="p">)</span>

    <span class="n">is_mapped</span><span class="p">,</span> <span class="n">map_info</span> <span class="o">=</span> <span class="n">buf</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">MapFlags</span><span class="o">.</span><span class="n">READ</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">is_mapped</span><span class="p">:</span>
        <span class="k">try</span><span class="p">:</span>
            <span class="n">image_array</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">(</span>
                <span class="p">(</span><span class="n">height</span><span class="p">,</span> <span class="n">width</span><span class="p">,</span> <span class="n">pixel_bytes</span><span class="p">),</span>
                <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint8</span><span class="p">,</span>
                <span class="nb">buffer</span><span class="o">=</span><span class="n">map_info</span><span class="o">.</span><span class="n">data</span>
            <span class="p">)</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span> <span class="c1"># extend array lifetime beyond subsequent unmap</span>
            <span class="k">return</span> <span class="n">preprocess</span><span class="p">(</span><span class="n">image_array</span><span class="p">[:,:,:</span><span class="mi">3</span><span class="p">])</span> <span class="c1"># RGBA -&gt; RGB</span>
        <span class="k">finally</span><span class="p">:</span>
            <span class="n">buf</span><span class="o">.</span><span class="n">unmap</span><span class="p">(</span><span class="n">map_info</span><span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">get_by_name</span><span class="p">(</span><span class="s1">&#39;s&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">get_static_pad</span><span class="p">(</span><span class="s1">&#39;sink&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">add_probe</span><span class="p">(</span>
    <span class="n">Gst</span><span class="o">.</span><span class="n">PadProbeType</span><span class="o">.</span><span class="n">BUFFER</span><span class="p">,</span>
    <span class="n">on_frame_probe</span>
<span class="p">)</span>

<span class="n">pipeline</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">State</span><span class="o">.</span><span class="n">PLAYING</span><span class="p">)</span>

<span class="k">try</span><span class="p">:</span>
    <span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="n">pipeline</span><span class="o">.</span><span class="n">get_bus</span><span class="p">()</span><span class="o">.</span><span class="n">timed_pop_filtered</span><span class="p">(</span>
            <span class="n">Gst</span><span class="o">.</span><span class="n">SECOND</span><span class="p">,</span>
            <span class="n">Gst</span><span class="o">.</span><span class="n">MessageType</span><span class="o">.</span><span class="n">EOS</span> <span class="o">|</span> <span class="n">Gst</span><span class="o">.</span><span class="n">MessageType</span><span class="o">.</span><span class="n">ERROR</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="n">msg</span><span class="p">:</span>
            <span class="n">text</span> <span class="o">=</span> <span class="n">msg</span><span class="o">.</span><span class="n">get_structure</span><span class="p">()</span><span class="o">.</span><span class="n">to_string</span><span class="p">()</span> <span class="k">if</span> <span class="n">msg</span><span class="o">.</span><span class="n">get_structure</span><span class="p">()</span> <span class="k">else</span> <span class="s1">&#39;&#39;</span>
            <span class="n">msg_type</span> <span class="o">=</span> <span class="n">Gst</span><span class="o">.</span><span class="n">message_type_get_name</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">type</span><span class="p">)</span>
            <span class="k">print</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;{msg.src.name}: [{msg_type}] {text}&#39;</span><span class="p">)</span>
            <span class="k">break</span>
<span class="k">finally</span><span class="p">:</span>
    <span class="nb">open</span><span class="p">(</span><span class="n">f</span><span class="s1">&#39;logs/{os.path.splitext(sys.argv[0])[0]}.pipeline.dot&#39;</span><span class="p">,</span> <span class="s1">&#39;w&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="p">(</span>
        <span class="n">Gst</span><span class="o">.</span><span class="n">debug_bin_to_dot_data</span><span class="p">(</span><span class="n">pipeline</span><span class="p">,</span> <span class="n">Gst</span><span class="o">.</span><span class="n">DebugGraphDetails</span><span class="o">.</span><span class="n">ALL</span><span class="p">)</span>
    <span class="p">)</span>
    <span class="n">pipeline</span><span class="o">.</span><span class="n">set_state</span><span class="p">(</span><span class="n">Gst</span><span class="o">.</span><span class="n">State</span><span class="o">.</span><span class="n">NULL</span><span class="p">)</span>
</code></pre></div>

<p>Some key points:</p>
<ul>
<li>In <code>buffer_to_image_tensor</code> we create a read-only mapping on the frame buffer memory then create a numpy array that points to the mapped memory.</li>
<li>We need to rearrange the image dimensions since Gstreamer has decoded to (height, width, channel) and this Pytorch model wants (channel, height, width).</li>
<li>In the pipeline below note the caps change from <code>video/x-raw(memory:NVVM)</code> to <code>video/x-raw</code> due to the newly added <code>nvvideoconvert</code> element. This element is transferring the decoded video buffer memory from GPU to CPU. The container has Gstreamer elements that support hardware video decoding so the <code>decodebin</code> element will use any compatible GPU to accelerate this. To make the decoded frames accessible for Gstreamer to map and read into Numpy we explicitly move them to host memory.</li>
</ul>
<details >
  <summary>Output: frames_into_pytorch.py</summary>
  <div>
    

<figure style="margin: 2rem 0">
    <img src="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/frames_into_pytorch.output.svg">
</figure>


  </div>
</details>

<details >
  <summary>Pipeline: frames_into_pytorch</summary>
  <div>
    








<a href="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/frames_into_pytorch.pipeline.png">
    <figure style="margin: 2rem 0">
        <img style="max-width: 100%; width: auto; height: auto;" src="/pbridger.github.io/docs/video_analytics_pytorch_pipeline/images/frames_into_pytorch.pipeline_hu72a2b805021a46ee07dd6bcb47dfba76_195243_800x0_resize_box_2.png" width="800" height="49">
        <figcaption><small></small></figcaption>
    </figure>
</a>


  </div>
</details>

<p>The above samples are nowhere near production ready but they show that the fundamentals of running machine learning inference on video don&rsquo;t have to be hard. We hooked up a pipeline that can seamlessly process many different video encodings and formats. Further, we are using the regular &ldquo;research&rdquo; Pytorch runtime which gives us a lot of flexibility.</p>
<p>To give you a quick feel for performance: this pipeline runs at around 100 FPS on a 2080Ti at &lt;80% utilization. Caveats: we are not doing full pre-processing or post-processing, but on the other hand this pipeline is completely unoptimized. We&rsquo;ll go into all this in a later post.</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">





</div>

 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      
  <nav id="TableOfContents">
  <ul>
    <li><a href="#intro">Intro</a></li>
    <li><a href="#step-0-baseline-cli-gstreamer-pipeline">Step 0: Baseline CLI Gstreamer pipeline</a></li>
    <li><a href="#step-1-get-frames-into-python">Step 1: Get frames into Python</a></li>
    <li><a href="#step-2-get-frames-into-pytorch">Step 2: Get frames into Pytorch</a></li>
  </ul>
</nav>

 
    </aside>
    
  </main>

  
</body>

</html>












